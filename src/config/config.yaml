# src/config/config.yaml
# ----------------------------
# Core configuration for Equity Forecasting Project
# Includes data paths, model parameters, training settings, early stopping, walk-forward validation,
# pipeline orchestration, and experiment tracking.
# Designed for reuse across CPU/GPU/Colab environments and for both global and equity-specific models.

# ----------------------------
# Section: Data Paths
# ----------------------------
data:
  raw_data_dir: "datalake/data/raw/"
  processed_data_dir: "datalake/data/processed/"
  features_data_dir: "datalake/data/features/"

# ----------------------------
# Section: Model Paths
# ----------------------------
model:
  # Directory for intermediate checkpoints during training
  checkpoints_dir: "datalake/models/checkpoints/"
  
  # Directory for final trained models
  trained_model_dir: "datalake/models/trained/"
  
  # Default trained model filename pattern
  # Supports dynamic naming: {model_type}_{num_equities}_{MMDD}.pth
  trained_model_file_pattern: "lstm_global_{num_equities}eqt_{MMDD}.pth"
  
  # Directory to save global models separately for easy reference
  global_model_dir: "datalake/models/trained/global/"

# ----------------------------
# Section: Predictions
# ----------------------------
predictions:
  test_dir: "datalake/predictions/test/"
  validation_dir: "datalake/predictions/validation/"
  production_dir: "datalake/predictions/production/"

# ----------------------------
# Section: Metadata
# ----------------------------
metadata:
  schema_dir: "datalake/metadata/schema/"
  stats_dir: "datalake/metadata/stats/"

# ----------------------------
# Section: Logging
# ----------------------------
logging:
  train_log_file: "datalake/logs/train.log"
  inference_log_file: "datalake/logs/inference.log"
  level: "INFO"

# ----------------------------
# Section: Evaluation
# ----------------------------
evaluation:
  metrics_dir: "datalake/evaluation/metrics/"
  reports_dir: "datalake/evaluation/reports/"

# ----------------------------
# Section: Experiments / Hyperparameter Optimization
# ----------------------------
experiments:
  optuna_trials_dir: "datalake/experiments/optuna/"
  wandb_runs_dir: "datalake/experiments/wandb/"

# ----------------------------
# Section: Model Parameters
# ----------------------------
model_params:
  input_size: 10         # Number of input features per time step
  hidden_size: 64        # LSTM hidden layer size
  num_layers: 2          # Number of LSTM layers
  output_size: 1         # Single-step forecast
  dropout: 0.3
  learning_rate: 0.001
  batch_size: 32
  num_epochs: 100
  device: "cpu"          # "cuda"  or "cpu"

# ----------------------------
# Section: Early Stopping
# ----------------------------
early_stopping:
  enabled: true
  patience: 10
  delta: 0.0001
  checkpoint_file: "datalake/models/checkpoints/best_model.pt"

# ----------------------------
# Section: Walk-Forward Validation (WFV)
# ----------------------------
walk_forward:
  enabled: true                        # Enable/disable WFV
  n_splits: 5                          # Number of rolling splits
  test_size_days: 30                    # Days in each test fold
  step_size_days: 15                    # Shift size between folds
  overlap: false                        # Allow overlapping test windows
  save_dir: "datalake/wfv/models/"      # Save models from each fold
  metrics: ["mape", "rmse", "r2"]       # Metrics to evaluate each fold
  evaluation_output: "datalake/wfv/reports/wfv_summary.json"  # Aggregated summary
  oof_predictions_dir: "datalake/wfv/oof_predictions/"         # Optional: store out-of-fold predictions

# ----------------------------
# Section: Pipeline Orchestration
# ----------------------------
pipeline:
  tasks:
    - ingestion
    - preprocessing
    - feature_generation
    - training
    - optimization
    - walkforward
    - ensembling
    - forecasting
  retries: 2         # Retry limit for failing task
  strict: true       # Fail-fast if true, skip failures if false
